# -*- coding: utf-8 -*-
"""Stroke Risk Predictive Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gpny4aLdQ22wlwRrQ8ubLS-YE6bMC51t
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

"""## **Data Loading**"""

stroke_risk = pd.read_csv('/content/drive/MyDrive/healthcare-dataset-stroke-data.csv')
stroke_risk

"""## **Explanatory Data Analysis (EDA)**

Untuk memahami struktur dataset stroke_risk, termasuk informasi tentang jumlah baris dan kolom, nama kolom, tipe data masing-masing kolom, serta jumlah nilai non-null di setiap kolom.
"""

stroke_risk.info()

""" Untuk mendapatkan statistik deskriptif dari kolom numerik di dataset"""

stroke_risk.describe()

"""### Univariate Analysis"""

stroke_risk.columns

# Assign categorical and numerical features
categorical_feature = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke']
numerical_feature = ['age', 'avg_glucose_level', 'bmi']

print('Fitur kategorikal:', categorical_feature)
print('Fitur numerikal:', numerical_feature)

"""### Categorical Analysis

Dari plot yang telah dibuat, didapatkan informasi bahwa dataset yang digunakan berisi lebih banyak data yang mengidap stroke dibanding yang normal.
"""

# Label dan warna untuk stroke
stroke_label = ['Stroke', 'Normal']
stroke_color = ["#8be04e", "#ebdc78"]

# Plot distribusi stroke
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
stroke_plot = sns.countplot(x=stroke_risk['stroke'], order=stroke_risk['stroke'].value_counts().index, palette=stroke_color)
stroke_plot.set_title('Distribusi dari Stroke')
stroke_plot.set_xticklabels(stroke_label, fontsize=15)
for p in stroke_plot.patches:
    stroke_plot.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))

plt.subplot(1, 2, 2)
stroke_pie = stroke_risk['stroke'].value_counts()
stroke_pie = stroke_pie.plot.pie(explode=[0.2, 0.2], labels=stroke_label, autopct='%1.1f%%', shadow=True, colors=stroke_color)
stroke_pie.set_title(label='Persentase Stroke')
plt.axis('off')

plt.show()

""" Dari plot yang dibuat, dapat diketahui bahwa distribusi jenis kelamin pada dataset lebih banyak Wanita dibandingkan Pria."""

# Menyesuaikan label berdasarkan nilai unik dalam gender
gender_labels = stroke_risk['gender'].unique()
gender_colors = ['navy', 'pink', 'purple'][:len(gender_labels)]  # Menyesuaikan warna sesuai jumlah kategori

# Plot distribusi gender
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
gender_plot = sns.countplot(x=stroke_risk['gender'], palette=gender_colors)
gender_plot.set_title('Distribusi dari Jenis Kelamin')
gender_plot.set_xticklabels(gender_labels, fontsize=15)
for p in gender_plot.patches:
    gender_plot.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))

plt.subplot(1, 2, 2)
gender_pie = stroke_risk['gender'].value_counts()
gender_pie = gender_pie.plot.pie(explode=[0.1] * len(gender_labels), labels=gender_labels, autopct='%1.1f%%', shadow=True, colors=gender_colors)
gender_pie.set_title(label='Persentase Jenis Kelamin')
plt.axis('off')

plt.show()

"""### Numerical Analysis"""

# Menampilkan histogram untuk fitur numerik
stroke_risk[['age', 'avg_glucose_level', 'bmi']].hist(bins=40, figsize=(15, 10))
plt.show()

"""### Multivariate Analysis

#### Categorical analysis

Pada *categorical analysis* ini dilakukan pengecekan rata-rata dari tiap fitur kategorikal terhadap stroke
"""

# Analisis Multivariat pada fitur kategorikal terhadap stroke
for i in range(len(categorical_feature) - 1):
    plt.figure(figsize=(12, 7))
    catp = sns.catplot(x='stroke', data=stroke_risk, hue=categorical_feature[i], kind='count', palette='pastel', edgecolor='.8')
    ax = catp.facet_axis(0, 0)

    for c in ax.containers:
        labels = [f'{(v.get_height()):.0f}' for v in c]
        ax.bar_label(c, labels=labels, label_type='edge')

    plt.title(f'Rata-Rata Stroke terhadap - {categorical_feature[i]}')
    plt.show()

categorical_feature

"""#### Numerical analysis"""

stroke_risk.select_dtypes(['int64', 'float64'])

sns.pairplot(stroke_risk.select_dtypes(['int64', 'float64']), diag_kind = 'kde')

# Membuat correlation matrix untuk fitur numerik
plt.figure(figsize=(10, 8))
correlation_matrix = stroke_risk[numerical_feature].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerical", size=20)
plt.show()

"""## **Data Preparation**

### Check Outlier
"""

# Visualisasi distribusi data dan outlier
plt.figure(figsize=(15, 20))

# Kolom-kolom numerik yang relevan untuk dataset stroke prediction
numerical_columns = ['age', 'avg_glucose_level', 'bmi']

# Visualisasi distplot dan boxplot untuk masing-masing kolom
for i, column in enumerate(numerical_columns):
    plt.subplot(len(numerical_columns), 2, i * 2 + 1)
    sns.histplot(stroke_risk[column], kde=True, color='DeepPink')
    plt.title(f'Distribusi: {column}')

    plt.subplot(len(numerical_columns), 2, i * 2 + 2)
    sns.boxplot(x=stroke_risk[column], color='SkyBlue')
    plt.title(f'Boxplot: {column}')

plt.tight_layout()
plt.show()

"""### Handling Outlier

Untuk mendeteksi dan menghapus nilai ekstrim (outlier) pada dataset dengan metode IQR (Interquartile Range).
"""

# Handling Outliers dengan metode IQR
data_outlier = stroke_risk[numerical_columns]

# Menghitung Q1, Q3, dan IQR
Q1 = data_outlier.quantile(0.25)
Q3 = data_outlier.quantile(0.75)
IQR = Q3 - Q1

# Mendefinisikan batas bawah dan atas
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Menghapus data stroke_risk
filtered_data = stroke_risk[
    ~((data_outlier < lower_bound) | (data_outlier > upper_bound)).any(axis=1)
]

print(f"Dataset sebelum menghapus outlier: {stroke_risk.shape}")
print(f"Dataset setelah menghapus outlier: {filtered_data.shape}")

# Menampilkan boxplot setelah outlier dihapus
plt.figure(figsize=(12, 7))
sns.boxplot(data=filtered_data[numerical_columns])
plt.title("Boxplot Setelah Menghapus Outlier")
plt.show()

"""### Handling Missing Value

Untuk menangani nilai yang tidak valid (misalnya bmi = 0) dengan menggantinya menggunakan nilai median.
"""

stroke_risk.isnull().sum()

stroke_risk['bmi'].describe()

stroke_risk['bmi'].fillna(stroke_risk['bmi'].mean(),inplace=True)
stroke_risk.isnull().sum()

"""### Feature Engineering"""

# Menghapus kolom 'id'
stroke_risk.drop('id',axis=1,inplace=True)
stroke_risk.head()

"""### Encoding"""

from sklearn.preprocessing import LabelEncoder

enc=LabelEncoder()

gender=enc.fit_transform(stroke_risk['gender'])

smoking_status=enc.fit_transform(stroke_risk['smoking_status'])

work_type=enc.fit_transform(stroke_risk['work_type'])
Residence_type=enc.fit_transform(stroke_risk['Residence_type'])
ever_married=enc.fit_transform(stroke_risk['ever_married'])

stroke_risk['work_type']=work_type

stroke_risk['ever_married']=ever_married
stroke_risk['Residence_type']=Residence_type
stroke_risk['smoking_status']=smoking_status
stroke_risk['gender']=gender

stroke_risk

stroke_risk.info()

#Correlation between all features
fig , ax = plt.subplots(figsize=(13,6))
sns.heatmap(stroke_risk.corr(), cmap="coolwarm", linecolor='white' , annot=True , linewidths=1 , ax=ax )

"""#### Train Test Split

Membagi dataset menjadi dua bagian, yaitu data latih (training set) dan data uji (test set), untuk membangun dan menguji performa model.
"""

X=stroke_risk.drop('stroke',axis=1)
Y=stroke_risk['stroke']

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=10)

print('Shape dari Xtrain', X_train.shape)
print('Shape dari Xest', X_test.shape)

"""#### Standarization

Melakukan standardisasi fitur agar berada dalam skala yang sama. Hal ini penting untuk algoritma yang sensitif terhadap skala fitur, seperti SVM, Logistic Regression.
"""

from sklearn.preprocessing import StandardScaler

std=StandardScaler()
X_train_std=std.fit_transform(X_train)
X_test_std=std.transform(X_test)

"""## **Modeling**

Membuat sebuah DataFrame untuk menyimpan hasil evaluasi performa model pada data latih dan data uji.
"""

# Membuat dataframe untuk menyimpan hasil evaluasi model
model = pd.DataFrame(index=['train_mse', 'test_mse'],
                     columns=['DecisionTree', 'LogisticRegression', 'SVM'])

import pandas as pd
from sklearn.tree import DecisionTreeClassifier


from sklearn.metrics import mean_squared_error, accuracy_score

# Membuat dataframe untuk menyimpan hasil evaluasi model
model = pd.DataFrame(index=['train_mse', 'test_mse'], columns=['DecisionTree', 'LogisticRegression', 'SVM'])

"""### Decision Tree

Melatih model Decision Tree Classifier dan mengevaluasi performanya pada data latih dan data uji menggunakan metrik Mean Squared Error (MSE).

 DecisionTreeClassifier diimpor dari library sklearn.tree. Model ini bekerja dengan membagi dataset menjadi cabang-cabang berdasarkan fitur tertentu untuk membuat keputusan.
"""

# Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(X_train_std, Y_train)
model.loc['train_mse', 'DecisionTree'] = mean_squared_error(Y_train, dt.predict(X_train_std))
model.loc['test_mse', 'DecisionTree'] = mean_squared_error(Y_test, dt.predict(X_test_std))

"""### Logistic Regression

Menerapkan model Logistic Regression untuk melakukan prediksi dan mengevaluasi performanya pada data latih dan data uji menggunakan metrik Mean Squared Error (MSE).

 Model Logistic Regression diimpor dari sklearn.linear_model menggunakan fungsi LogisticRegression. Model ini adalah algoritma klasifikasi yang berbasis probabilitas.
"""

# Logistic Regression
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train_std, Y_train)
model.loc['train_mse', 'LogisticRegression'] = mean_squared_error(Y_train, lr.predict(X_train_std))
model.loc['test_mse', 'LogisticRegression'] = mean_squared_error(Y_test, lr.predict(X_test_std))

"""### Support Vector Machine (SVM)

Mengaplikasikan model Support Vector Machine (SVM) untuk melakukan klasifikasi dan mengevaluasi performa model pada data latih dan data uji dengan menggunakan metrik Mean Squared Error (MSE).

 Model Support Vector Classifier (SVC) diimpor dari modul sklearn.svm. Algoritma SVM bekerja dengan mencari hyperplane terbaik untuk memisahkan kelas dalam data.
"""

# Support Vector Machine (SVM)
from sklearn.svm import SVC

sv = SVC()
sv.fit(X_train_std, Y_train)
model.loc['train_mse', 'SVM'] = mean_squared_error(Y_train, sv.predict(X_train_std))
model.loc['test_mse', 'SVM'] = mean_squared_error(Y_test, sv.predict(X_test_std))

"""### Model Evaluation

Menghitung dan membandingkan nilai Mean Squared Error (MSE) dari ketiga model (Decision Tree, Logistic Regression, dan SVM) pada data latih (train) dan data uji (test).
"""

# Buat dataframe untuk menyimpan MSE pada data train dan test
mse = pd.DataFrame(columns=['train', 'test'], index=['DecisionTree', 'LogisticRegression', 'SVM'])

# Dictionary untuk setiap model
model_dict = {'DecisionTree': dt, 'LogisticRegression': lr, 'SVM': sv}

# Menghitung Mean Squared Error (MSE) pada train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(Y_train, model.predict(X_train_std)) / 1e3
    mse.loc[name, 'test'] = mean_squared_error(Y_test, model.predict(X_test_std)) / 1e3

# Menampilkan MSE
print(mse)

""" Berdasarkan hasil evaluasi yang didapatkan:

 - DecisionTree memiliki MSE 0 pada data latih

 - LogisticRegression dan SVM memiliki performa yang lebih stabil antara data latih dan data uji, dengan MSE pada data uji lebih rendah dibandingkan Decision Tree.
"""

# Plot hasil MSE
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Membuat tabel akurasi dari masing-masing metode
from sklearn.metrics import accuracy_score # Import accuracy_score

accuracy = pd.DataFrame(columns=['Akurasi'], index=['DecisionTree', 'LogisticRegression', 'SVM'])

for name, model in model_dict.items():
    acc = accuracy_score(Y_test, model.predict(X_test_std))
    accuracy.loc[name, 'Akurasi'] = acc

# Menampilkan tabel akurasi
print(accuracy)

# Plot tabel akurasi
fig, ax = plt.subplots()
accuracy.sort_values(by='Akurasi', ascending=True).plot(kind='barh', ax=ax, zorder=3, color="skyblue")
ax.set_title('Tabel Akurasi Model', fontsize=16)
ax.set_xlabel('Akurasi', fontsize=14)
ax.set_ylabel('Model', fontsize=14)
ax.grid(zorder=0)
plt.show()

import random

# Prediksi untuk 3 data acak dari X_test
random_indices = random.sample(range(len(X_test)), 3)  # Pilih 3 indeks acak
prediksi = X_test.iloc[random_indices].copy()
pred_dict = {'y_true': Y_test.iloc[random_indices]}  # Ambil nilai target sebenarnya

for name, model in model_dict.items():
    # Standardize the prediction data before feeding it to the model
    prediksi_std = std.transform(prediksi)
    pred_dict['prediksi_' + name] = model.predict(prediksi_std).round(1)

# Menampilkan hasil prediksi
pd.DataFrame(pred_dict)

""" Hasil keluaran berupa tabel yang menampilkan perbandingan antara nilai target sebenarnya (y_true) dengan hasil prediksi dari beberapa model (DecisionTree, LogisticRegression, dan SVM).

 Semua model memberikan prediksi 0 untuk ketiga sampel, yang sesuai dengan nilai y_true.
"""