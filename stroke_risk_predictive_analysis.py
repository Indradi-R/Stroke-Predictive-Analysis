# -*- coding: utf-8 -*-
"""Stroke Risk Predictive Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gpny4aLdQ22wlwRrQ8ubLS-YE6bMC51t
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

"""##**Data Loading**"""

stroke_risk = pd.read_csv('/content/drive/MyDrive/healthcare-dataset-stroke-data.csv')
stroke_risk

"""##**Explanatory Data Analysis (EDA)**"""

stroke_risk.info()

stroke_risk.describe()

"""### Univariate Analysis"""

stroke_risk.columns

# Assign categorical and numerical features
categorical_feature = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke']
numerical_feature = ['age', 'avg_glucose_level', 'bmi']

print('Fitur kategorikal:', categorical_feature)
print('Fitur numerikal:', numerical_feature)

"""### Categorical Analysis"""

# Label dan warna untuk stroke
stroke_label = ['Stroke', 'Normal']
stroke_color = ["#8be04e", "#ebdc78"]

# Plot distribusi stroke
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
stroke_plot = sns.countplot(x=stroke_risk['stroke'], order=stroke_risk['stroke'].value_counts().index, palette=stroke_color)
stroke_plot.set_title('Distribusi dari Stroke')
stroke_plot.set_xticklabels(stroke_label, fontsize=15)
for p in stroke_plot.patches:
    stroke_plot.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))

plt.subplot(1, 2, 2)
stroke_pie = stroke_risk['stroke'].value_counts()
stroke_pie = stroke_pie.plot.pie(explode=[0.2, 0.2], labels=stroke_label, autopct='%1.1f%%', shadow=True, colors=stroke_color)
stroke_pie.set_title(label='Persentase Stroke')
plt.axis('off')

plt.show()

# Menyesuaikan label berdasarkan nilai unik dalam gender
gender_labels = stroke_risk['gender'].unique()
gender_colors = ['navy', 'pink', 'purple'][:len(gender_labels)]  # Menyesuaikan warna sesuai jumlah kategori

# Plot distribusi gender
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
gender_plot = sns.countplot(x=stroke_risk['gender'], palette=gender_colors)
gender_plot.set_title('Distribusi dari Jenis Kelamin')
gender_plot.set_xticklabels(gender_labels, fontsize=15)
for p in gender_plot.patches:
    gender_plot.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))

plt.subplot(1, 2, 2)
gender_pie = stroke_risk['gender'].value_counts()
gender_pie = gender_pie.plot.pie(explode=[0.1] * len(gender_labels), labels=gender_labels, autopct='%1.1f%%', shadow=True, colors=gender_colors)
gender_pie.set_title(label='Persentase Jenis Kelamin')
plt.axis('off')

plt.show()

"""### Numerical Analysis"""

# Menampilkan histogram untuk fitur numerik
stroke_risk[['age', 'avg_glucose_level', 'bmi']].hist(bins=40, figsize=(15, 10))
plt.show()

"""### Multivariate Analysis

#### Categorical analysis
"""

# Analisis Multivariat pada fitur kategorikal terhadap stroke
for i in range(len(categorical_feature) - 1):
    plt.figure(figsize=(12, 7))
    catp = sns.catplot(x='stroke', data=stroke_risk, hue=categorical_feature[i], kind='count', palette='pastel', edgecolor='.8')
    ax = catp.facet_axis(0, 0)

    for c in ax.containers:
        labels = [f'{(v.get_height()):.0f}' for v in c]
        ax.bar_label(c, labels=labels, label_type='edge')

    plt.title(f'Rata-Rata Stroke terhadap - {categorical_feature[i]}')
    plt.show()

categorical_feature

"""#### Numerical analysis"""

stroke_risk.select_dtypes(['int64', 'float64'])

sns.pairplot(stroke_risk.select_dtypes(['int64', 'float64']), diag_kind = 'kde')

# Membuat correlation matrix untuk fitur numerik
plt.figure(figsize=(10, 8))
correlation_matrix = stroke_risk[numerical_feature].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerical", size=20)
plt.show()

"""## **Data Preparation**

### Handling Missing Value
"""

stroke_risk.isnull().sum()

stroke_risk['bmi'].describe()

stroke_risk['bmi'].fillna(stroke_risk['bmi'].mean(),inplace=True)
stroke_risk.isnull().sum()

"""### Feature Engineering"""

# Menghapus kolom 'id'
stroke_risk.drop('id',axis=1,inplace=True)
stroke_risk.head()

"""### Encoding"""

from sklearn.preprocessing import LabelEncoder

enc=LabelEncoder()

gender=enc.fit_transform(stroke_risk['gender'])

smoking_status=enc.fit_transform(stroke_risk['smoking_status'])

work_type=enc.fit_transform(stroke_risk['work_type'])
Residence_type=enc.fit_transform(stroke_risk['Residence_type'])
ever_married=enc.fit_transform(stroke_risk['ever_married'])

stroke_risk['work_type']=work_type

stroke_risk['ever_married']=ever_married
stroke_risk['Residence_type']=Residence_type
stroke_risk['smoking_status']=smoking_status
stroke_risk['gender']=gender

stroke_risk

stroke_risk.info()

#Correlation between all features
fig , ax = plt.subplots(figsize=(13,6))
sns.heatmap(stroke_risk.corr(), cmap="coolwarm", linecolor='white' , annot=True , linewidths=1 , ax=ax )

"""#### Train Test Split"""

X=stroke_risk.drop('stroke',axis=1)
Y=stroke_risk['stroke']

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=10)

print('Shape dari Xtrain', X_train.shape)
print('Shape dari Xest', X_test.shape)

"""#### Standarization"""

from sklearn.preprocessing import StandardScaler

std=StandardScaler()
X_train_std=std.fit_transform(X_train)
X_test_std=std.transform(X_test)

"""## **Modeling**"""

# Membuat dataframe untuk menyimpan hasil evaluasi model
model = pd.DataFrame(index=['train_mse', 'test_mse'],
                     columns=['DecisionTree', 'LogisticRegression', 'SVM'])

import pandas as pd
from sklearn.tree import DecisionTreeClassifier


from sklearn.metrics import mean_squared_error, accuracy_score

# Membuat dataframe untuk menyimpan hasil evaluasi model
model = pd.DataFrame(index=['train_mse', 'test_mse'], columns=['DecisionTree', 'LogisticRegression', 'SVM'])

"""### Decision Tree"""

# Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(X_train_std, Y_train)
model.loc['train_mse', 'DecisionTree'] = mean_squared_error(Y_train, dt.predict(X_train_std))
model.loc['test_mse', 'DecisionTree'] = mean_squared_error(Y_test, dt.predict(X_test_std))

"""### Logistic Regression"""

# Logistic Regression
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train_std, Y_train)
model.loc['train_mse', 'LogisticRegression'] = mean_squared_error(Y_train, lr.predict(X_train_std))
model.loc['test_mse', 'LogisticRegression'] = mean_squared_error(Y_test, lr.predict(X_test_std))

"""### Support Vector Machine (SVM)"""

# Support Vector Machine (SVM)
from sklearn.svm import SVC

sv = SVC()
sv.fit(X_train_std, Y_train)
model.loc['train_mse', 'SVM'] = mean_squared_error(Y_train, sv.predict(X_train_std))
model.loc['test_mse', 'SVM'] = mean_squared_error(Y_test, sv.predict(X_test_std))

"""### Model Evaluation"""

# Buat dataframe untuk menyimpan MSE pada data train dan test
mse = pd.DataFrame(columns=['train', 'test'], index=['DecisionTree', 'LogisticRegression', 'SVM'])

# Dictionary untuk setiap model
model_dict = {'DecisionTree': dt, 'LogisticRegression': lr, 'SVM': sv}

# Menghitung Mean Squared Error (MSE) pada train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(Y_train, model.predict(X_train_std)) / 1e3
    mse.loc[name, 'test'] = mean_squared_error(Y_test, model.predict(X_test_std)) / 1e3

# Menampilkan MSE
print(mse)

# Plot hasil MSE
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Membuat tabel akurasi dari masing-masing metode
from sklearn.metrics import accuracy_score # Import accuracy_score

accuracy = pd.DataFrame(columns=['Akurasi'], index=['DecisionTree', 'LogisticRegression', 'SVM'])

for name, model in model_dict.items():
    acc = accuracy_score(Y_test, model.predict(X_test_std))
    accuracy.loc[name, 'Akurasi'] = acc

# Menampilkan tabel akurasi
print(accuracy)

# Plot tabel akurasi
fig, ax = plt.subplots()
accuracy.sort_values(by='Akurasi', ascending=True).plot(kind='barh', ax=ax, zorder=3, color="skyblue")
ax.set_title('Tabel Akurasi Model', fontsize=16)
ax.set_xlabel('Akurasi', fontsize=14)
ax.set_ylabel('Model', fontsize=14)
ax.grid(zorder=0)
plt.show()

import random

# Prediksi untuk 3 data acak dari X_test
random_indices = random.sample(range(len(X_test)), 3)  # Pilih 3 indeks acak
prediksi = X_test.iloc[random_indices].copy()
pred_dict = {'y_true': Y_test.iloc[random_indices]}  # Ambil nilai target sebenarnya

for name, model in model_dict.items():
    # Standardize the prediction data before feeding it to the model
    prediksi_std = std.transform(prediksi)
    pred_dict['prediksi_' + name] = model.predict(prediksi_std).round(1)

# Menampilkan hasil prediksi
pd.DataFrame(pred_dict)